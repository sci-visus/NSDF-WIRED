{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca04e56-fa0e-4840-9981-379cc545ae2a",
   "metadata": {},
   "source": [
    "# Create .PNG images of all timesteps from `idx_calls` loading from netCDF files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac89f1-da13-4a78-b05f-ac4a17fea961",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb7475-1c3d-41ef-92a2-dbaaaba8ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # <1>\n",
    "import os # <2>\n",
    "import xarray as xr # <3>\n",
    "import time # <4>\n",
    "import datetime # <4>\n",
    "import pandas as pd # <5>\n",
    "import matplotlib # <6>\n",
    "import matplotlib.pyplot as plt # <6>\n",
    "import cartopy.crs as ccrs # <6>\n",
    "import pickle # <7>\n",
    "from tqdm import tqdm # <8>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5384e-abd6-4982-b5b0-87c888d6ea81",
   "metadata": {},
   "source": [
    "1. For numerical work\n",
    "2. For accessing file system\n",
    "3. For loading NetCDF files, for metadata\n",
    "4. Used for processing netCDF time data\n",
    "5. Used for indexing via metadata\n",
    "6. For plotting\n",
    "7. For exporting the dictionary of issue files at the end of notebook and importing `idx_calls.pkl`\n",
    "8. Accessory, used to generate progress bar for running for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40349c30-d1ce-4695-9a01-170824dfb3df",
   "metadata": {},
   "source": [
    "## Get path to original firesmoke data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12053d7-0394-49af-b74d-8d0f9be7ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_dir = \"/usr/sci/cedmav/data/firesmoke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a0fb9-fc95-442d-b9eb-4196cc9582f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\"BSC18CA12-01\", \"BSC00CA12-01\", \"BSC06CA12-01\", \"BSC12CA12-01\"] # <1>\n",
    "start_dates = [\"20210304\", \"20210304\", \"20210304\", \"20210303\"] # <1>\n",
    "end_dates = [\"20240627\", \"20240627\", \"20240627\", \"20240627\"] # <1>\n",
    "\n",
    "id_dates = {ids[i]: {\"start_date\": start_dates[i], \"end_date\": end_dates[i]} for i in range(len(ids))} # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1090bde8-7d93-4ccf-8757-15090eaa4018",
   "metadata": {},
   "source": [
    "1. Date ranges for each smoke forecast dataset.\n",
    "2. Create dictionary of all file names using information above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5385e5-517a-45f4-8173-ba27ed77fa0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In this section, we load metadata from 381x1041 and 381x1081 files using `xr.open_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01758d7f-16e2-43ab-a47a-d8503bb1b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_s = f'{netcdf_dir}/{ids[1]}/dispersion_20210304.nc' # <1>\n",
    "file_b = f'{netcdf_dir}/{ids[1]}/dispersion_20240101.nc' # <1>\n",
    "\n",
    "ds_s = xr.open_dataset(file_s) # <2>\n",
    "ds_b = xr.open_dataset(file_b) # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a24d9-f3af-4878-89c1-a63a5159be55",
   "metadata": {},
   "source": [
    "1. Path to small and big files\n",
    "2. Open metadata of each file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a37bd-1218-4096-bd68-f85e12dbf566",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate derived metadata using original metadata above to create coordinates\n",
    "### We'll use this for creating our visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488084c-f982-4d03-ab25-7c81679aef1c",
   "metadata": {},
   "source": [
    "#### Calculate latitude and longitude grid for each set of files' metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8287e0-dd1b-486a-850f-4ac8f229a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_s = np.linspace(ds_s.XORIG, ds_s.XORIG + ds_s.XCELL * (ds_s.NCOLS - 1), ds_s.NCOLS)\n",
    "latitude_s = np.linspace(ds_s.YORIG, ds_s.YORIG + ds_s.YCELL * (ds_s.NROWS - 1), ds_s.NROWS)\n",
    "\n",
    "longitude_b = np.linspace(ds_b.XORIG, ds_b.XORIG + ds_b.XCELL * (ds_b.NCOLS - 1), ds_b.NCOLS)\n",
    "latitude_b = np.linspace(ds_b.YORIG, ds_b.YORIG + ds_b.YCELL * (ds_b.NROWS - 1), ds_b.NROWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92596e1d-7394-493c-9b77-74c0a6358cbd",
   "metadata": {},
   "source": [
    "#### The timestamps used in the files may not be intuitive. The following utility function returns the desired pandas timestamp based on your date and time of interest. \n",
    "\n",
    "##### When you index the data at a desired time, use this function to get the timestamp you need to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca4f7c-43fa-4bf8-ad57-daa9a6e1d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tflag(tflag):\n",
    "    \"\"\"\n",
    "    Return the tflag as a datetime object\n",
    "    :param list tflag: a list of two int32, the 1st representing date and 2nd representing time\n",
    "    \"\"\"\n",
    "    date = int(tflag[0]) # <1>\n",
    "    year = date // 1000 # first 4 digits of tflag[0] # <1>\n",
    "    day_of_year = date % 1000 # last 3 digits of tflag[0] # <1>\n",
    "\n",
    "    final_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=day_of_year - 1) # <2>\n",
    "\n",
    "    time = int(tflag[1]) # <3>\n",
    "    hours = time // 10000 # first 2 digits of tflag[1] # <3>\n",
    "    minutes = (time % 10000) // 100 # 3rd and 4th digits of tflag[1] # <3>\n",
    "    seconds = time % 100  # last 2 digits of tflag[1] # <3>\n",
    "\n",
    "    full_datetime = datetime.datetime(year, final_date.month, final_date.day, hours, minutes, seconds) # <4>\n",
    "    return full_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427be384-228c-4a97-958b-b4cd8eb8a6e6",
   "metadata": {},
   "source": [
    "1. Obtain year and day of year from tflag[0] (date)\n",
    "2. Create datetime object representing date\n",
    "3. Obtain hour, mins, and secs from tflag[1] (time)\n",
    "4. Create final datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488bbfc-06ef-407d-953d-5266255e00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(year, month, day, hour):\n",
    "    \"\"\"\n",
    "    return a pandas timestamp using the given date-time arguments\n",
    "    :param int year: year\n",
    "    :param int month: month\n",
    "    :param int day: day\n",
    "    :param int hour: hour\n",
    "    \"\"\"\n",
    "    full_datetime = datetime.datetime(year, month, day, hour) # <1>\n",
    "    \n",
    "    year = full_datetime.year # <2>\n",
    "    day_of_year = full_datetime.timetuple().tm_yday # <2>\n",
    "    hours = full_datetime.hour # <2>\n",
    "    minutes = full_datetime.minute # <2>\n",
    "    seconds = full_datetime.second # <2>\n",
    "\n",
    "    tflag0 = year * 1000 + day_of_year # <3>\n",
    "    tflag1 = hours * 10000 + minutes * 100 + seconds # <3>\n",
    "\n",
    "    return pd.Timestamp(full_datetime) # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2386f-af27-4ce8-8d64-fac961ed4a0d",
   "metadata": {},
   "source": [
    "1. Convert year, month, day, and hour to a datetime object\n",
    "2. Extract components from the datetime object\n",
    "3. Compute tflag[0] and tflag[1]\n",
    "4. Return the Pandas Timestamp object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf7b30-a4d7-42e2-acbf-5609e14584c0",
   "metadata": {},
   "source": [
    "## Import sequence of data slices to get at what time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc32aa-c8bf-41c0-96b3-f2c23aeb029e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('idx_calls_v4.pkl', 'rb') as f: # <1>\n",
    "    idx_calls = pickle.load(f) # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9412cd-23a1-4a6f-ba08-dc67d0ff8abd",
   "metadata": {},
   "source": [
    "1. Load idx_calls from file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bb5f3-d231-4fe7-8be6-69c53e78df99",
   "metadata": {},
   "source": [
    "## Create the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d90a3-6e1a-4b30-92ff-d1eee3b488fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/usr/sci/scratch_nvme/arleth/dump/netcdf_frames\" # <1>\n",
    "\n",
    "my_norm = \"log\" # <2>\n",
    "my_extent_s = [np.min(longitude_s), np.max(longitude_s), np.min(latitude_s), np.max(latitude_s)]# <2>\n",
    "my_extent_b = [np.min(longitude_b), np.max(longitude_b), np.min(latitude_b), np.max(latitude_b)]# <2>\n",
    "my_aspect = 'auto'# <2>\n",
    "my_origin = 'lower'# <2>\n",
    "my_cmap = 'hot'# <2>\n",
    "\n",
    "issue_files = {} # <3>\n",
    "\n",
    "frame_num = 0 # <4>\n",
    "\n",
    "for call in tqdm(idx_calls): # <5>\n",
    "    curr_id = call[0] # <6>\n",
    "    curr_file = call[1] # <6>\n",
    "    curr_date = call[2] # <6>\n",
    "    tstep_index = call[3] # <6>\n",
    "    \n",
    "    ds = xr.open_dataset(f'{netcdf_dir}/{curr_id}/{curr_file}') # <7>\n",
    "\n",
    "    ds_vals = np.squeeze(ds['PM25'].values) # <8>\n",
    "\n",
    "    data_at_time = ds_vals[tstep_index] # <9>\n",
    "\n",
    "    t = pd.Timestamp(parse_tflag(ds['TFLAG'].values[tstep_index][0])) # <10>\n",
    "    \n",
    "    try: # <11>\n",
    "        my_fig, my_plt = plt.subplots(figsize=(15, 6), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "        curr_extent = my_extent_s if ds['PM25'].shape[3] == 1041 else my_extent_b # <12>\n",
    "        plot = my_plt.imshow(data_at_time, norm=my_norm, extent=curr_extent, aspect=my_aspect, origin=my_origin, cmap=my_cmap)\n",
    "        my_fig.colorbar(plot,location='right', label='ug/m^3')\n",
    "        my_plt.coastlines()\n",
    "        my_plt.gridlines(draw_labels=True)\n",
    "        my_fig.suptitle(f'Ground Level Concentration of PM2.5 Microns and Smaller\\n{t}') # <13>\n",
    "        \n",
    "        my_plt.text(0.5, -0.1, 'Original NetCDF Data', ha='center', va='center', transform=my_plt.transAxes) # <14>\n",
    "        \n",
    "        plt.savefig(folder + \"/frames%05d.png\" % frame_num, dpi=280) # <15>\n",
    "        plt.close(my_fig);  # <16>\n",
    "        matplotlib.pyplot.close()\n",
    "    except: # <17>\n",
    "        print(f\"issue! {t}\") # <17>\n",
    "        issue_files[t] = data_at_time # <17>\n",
    "        continue # <17>\n",
    "    frame_num = frame_num + 1 # <18>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96953c-d308-4a9c-9da7-7959aba17c63",
   "metadata": {},
   "source": [
    "1. Directory of environment to save frames\n",
    "2. Set parameters for creating visualization of each timestep with matplotlib.\n",
    "3. Dictionary to keep track of files with 'issues'.\n",
    "4. To track what frame we're on in the following loop.\n",
    "5. For all timesteps create visualization of firesmoke at time.\n",
    "6. Get instructions from call.\n",
    "7. Open the current file with xarray.\n",
    "8. Get the PM25 values, squeeze out empty axis.\n",
    "9. Get PM2.5 values at tstep_index and visualize them.\n",
    "10. Get the timestamp for titling our plot, use hour 'h'.\n",
    "11. Catch exceptions accordingly.\n",
    "12. Extent is either with the 381x1041 lons/lats or 381x1081 lons/lats.\n",
    "13. Add a title with the time information.\n",
    "14. Add an additional caption for context.\n",
    "15. Save the visualization as a frame.\n",
    "16. Close the figure after saving.\n",
    "17. Print exception if one is found and save issue in issue dictionary using timestamp `t` as key.\n",
    "18. Whether exception or not, next frame count to align with idx script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa9100-8e6b-4573-bd6a-4dab86eb4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_netcdf_issues.pkl', 'wb') as f: # <1>\n",
    "    pickle.dump(issue_files, f) # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3b447-65f6-4b12-bce2-1d7dc5388d2a",
   "metadata": {},
   "source": [
    "1. Save 'issue_files' to review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
