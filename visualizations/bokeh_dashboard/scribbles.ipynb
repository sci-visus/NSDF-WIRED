{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0cf9120-d003-4b92-b33d-5486baf9f3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ov.LoadDataset(http://atlantis.sci.utah.edu/mod_visus?dataset=UBC_fire_smoke_BSC&cached=1)\n",
      "PM25\n",
      "Adding field  PM25 shape  [27357, 381, 1081, 21] dtype  float32 labels  ['time', 'ROW', 'COL', 'resolution'] Max Resolution  20\n"
     ]
    }
   ],
   "source": [
    "# for accessing file system\n",
    "import os\n",
    "\n",
    "# for numerical work\n",
    "import numpy as np\n",
    "\n",
    "# for loading netcdf files, for metadata\n",
    "import xarray as xr\n",
    "\n",
    "# for connecting OpenVisus framework to xarray\n",
    "# from https://github.com/sci-visus/openvisuspy,\n",
    "from openvisuspy.xarray_backend import OpenVisusBackendEntrypoint\n",
    "\n",
    "# Used for processing netCDF time data\n",
    "import requests\n",
    "\n",
    "# Used for indexing via metadata\n",
    "import pandas as pd\n",
    "\n",
    "# local modules\n",
    "from util import *\n",
    "\n",
    "os.environ[\"VISUS_CACHE\"] = \"./visus_cache_can_be_erased\"\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"\"\n",
    "\n",
    "# whether to download tiny netcdf or not\n",
    "download = False\n",
    "\n",
    "local_netcdf = \"firesmoke_metadata.nc\"\n",
    "\n",
    "if download:\n",
    "    # path to tiny NetCDF\n",
    "    url = \"https://github.com/sci-visus/NSDF-WIRED/raw/main/data/firesmoke_metadata.nc\"\n",
    "\n",
    "    # Download the file using requests\n",
    "    response = requests.get(url)\n",
    "    with open(local_netcdf, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# open tiny netcdf with xarray and OpenVisus backend\n",
    "ds = xr.open_dataset(local_netcdf, engine=OpenVisusBackendEntrypoint)\n",
    "\n",
    "##### Process all metadata of file #####\n",
    "### Lat/Lon ###\n",
    "# get metadata to compute lon and lat\n",
    "xorig = ds.XORIG\n",
    "yorig = ds.YORIG\n",
    "xcell = ds.XCELL\n",
    "ycell = ds.YCELL\n",
    "ncols = ds.NCOLS\n",
    "nrows = ds.NROWS\n",
    "\n",
    "longitude = np.linspace(xorig, xorig + xcell * (ncols - 1), ncols)\n",
    "latitude = np.linspace(yorig, yorig + ycell * (nrows - 1), nrows)\n",
    "\n",
    "# Create coordinates for lat and lon (credit: Aashish Panta)\n",
    "ds.coords[\"lat\"] = (\"ROW\", latitude)\n",
    "ds.coords[\"lon\"] = (\"COL\", longitude)\n",
    "\n",
    "# Replace col and row dimensions with newly calculated lon and lat arrays (credit: Aashish Panta)\n",
    "ds = ds.swap_dims({\"COL\": \"lon\", \"ROW\": \"lat\"})\n",
    "\n",
    "### Timestamps ###\n",
    "# get all tflags\n",
    "tflag_values = ds[\"TFLAG\"].values\n",
    "\n",
    "# to store pandas timestamps\n",
    "timestamps = []\n",
    "\n",
    "# convert all tflags to pandas timestamps, store in timestamps list\n",
    "for tflag in tflag_values:\n",
    "    timestamps.append(pd.Timestamp(parse_tflag(tflag[0])))\n",
    "\n",
    "# set coordinates to each timestep with these pandas timestamps\n",
    "ds.coords[\"time\"] = (\"time\", timestamps)\n",
    "\n",
    "\n",
    "##### Functions for bokeh to access data #####\n",
    "def get_latslons():\n",
    "    \"\"\"\n",
    "    Return a numpy array of all lats and lons used in dataset in mercator coordinates\n",
    "    \"\"\"\n",
    "    # get list of latitudes and longitudes\n",
    "    data_stacked_index = ds[\"PM25\"][0].stack(lat_lon=[\"lat\", \"lon\"])\n",
    "\n",
    "    # numpy array to return\n",
    "    mercator_latlons = np.zeros((np.shape(data_stacked_index)[1], 2))\n",
    "    for i, tup in enumerate(latlon_to_mercator_iter(data_stacked_index.lat_lon.values)):\n",
    "        mercator_latlons[i][0] = tup[0]\n",
    "        mercator_latlons[i][1] = tup[1]\n",
    "\n",
    "    return mercator_latlons\n",
    "\n",
    "\n",
    "def get_pm25(date, res):\n",
    "    \"\"\"\n",
    "    Return a numpy array of pm2.5 values for all hours of given date at specified resolution\n",
    "    :param string date: Date to query data for, in format \"YYYY-MM-DD\"\n",
    "    :param int res: IDX resolution to use\n",
    "    \"\"\"\n",
    "    # get time range\n",
    "    year = int(date[0:4])\n",
    "    month = int(date[5:7])\n",
    "    day = int(date[-2:])\n",
    "    start_time = get_timestamp(year, month, day, 0)\n",
    "    end_time = get_timestamp(year, month, day, 23)\n",
    "    # get slice\n",
    "    data_array_at_time = ds[\"PM25\"].loc[start_time:end_time, :, :, res]\n",
    "    return data_array_at_time.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32112dbf-e3c2-4652-a199-6126dfe949c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Max Resolution:  20\n",
      "Time: 0, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 1, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 2, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 3, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 4, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 5, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 6, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 7, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 8, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 9, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 10, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 11, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 12, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 13, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 14, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 15, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 16, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 17, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 18, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 19, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 20, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 21, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 22, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n",
      "Time: 23, max_resolution: 20, logic_box=(0, 1081, 0, 381), field: PM25\n"
     ]
    }
   ],
   "source": [
    "arr = get_pm25(\"2021-03-04\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a645e179-86b2-4d0a-a3e0-a1819dcd246a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 381, 1081)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6220a7-2240-4f74-af9f-698fe330b2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
